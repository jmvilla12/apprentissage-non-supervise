{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25aad299",
   "metadata": {},
   "source": [
    "# UV TRNU.CSN - Data and Machine Learning\n",
    "## Unsupervised learning - TP Clustering - 2025\n",
    "\n",
    "Christelle Garnier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0935aa6c",
   "metadata": {},
   "source": [
    "### Aim of the TP\n",
    "\n",
    "The aim of this practical work is:\n",
    "- to perform clustering on data in order to automatically create categories by leveraging the classes and functions provided by the `Scikit-Learn` and `SciPy` libraries. \n",
    "- The methods to be implemented and tested are hierarchical agglomerative clustering and K-means algorithms. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9663c31a",
   "metadata": {},
   "source": [
    "### Dataset 'hotels.csv'\n",
    "\n",
    "The work consists of performing a clustering on the data contained in the file 'hotels.csv' available on MyLearningSpace. \n",
    "\n",
    "Start by looking at the file. It contains information about a set of hotels: NOM (name), PAYS (country), ETOILE (number of stars), CONFORT (comfort rating), CHAMBRE (number of rooms), CUISINE (food rating), SPORT (sport rating), PLAGE (beach rating), PRIX (price per night in euros).\n",
    "\n",
    "The objective is to automatically group hotels of similar standing. The clustering can  identify several categories of hotels, which will be compared with the star-based classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc500f9",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e3717f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#TODO ADD other needed libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9840f120",
   "metadata": {},
   "source": [
    "### 1. Reading the Data\n",
    "\n",
    "1. Load the file 'hotels.csv' using `read_csv()` from the `pandas` library. Check the import by using the methods and attributes available for the `DataFrame` class, such as `info()`, `describe()`, `shape`, and `head()`.\n",
    "\n",
    "1. Decide which variables to keep for clustering and store the corresponding columns separately so that the values of these variables can be retrieved later. In particular, you will need to name the hotels in graphical representations of the clusters.\n",
    "\n",
    "1. Remove the unused columns with the `drop()` method of the `DataFrame` class.\n",
    "\n",
    "1. Store the names of the remaining columns using the `columns` attribute of the `DataFrame` class so that the names of the variables/features used for clustering can be retrieved later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a30b119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f5f56f4",
   "metadata": {},
   "source": [
    "### 2. Exploring the Data\n",
    "\n",
    "Once the data has been imported and selected, begin with a preliminary analysis to identify relationships between the variables.\n",
    "\n",
    "1. Compute the correlation coefficients between all pairs of numerical variables using the `corr()` method of the `DataFrame` class and visualize the correlation matrix as a heatmap using the `heatmap()` function from the `seaborn` library. \n",
    "\n",
    "1. Identify which variables are the most strongly correlated (positively and negatively), and which ones show the weakest correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c49fb3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13297bb3",
   "metadata": {},
   "source": [
    "### 3. Preprocessing the Data\n",
    "To perform clustering, the data must be centered and scaled:\n",
    "\n",
    "1. First, convert the `DataFrame` object into a `numpy` array by using the `to_numpy()` method of the `DataFrame` class.\n",
    "\n",
    "1. Next, use the `StandardScaler` class from `sklearn.preprocessing` to center and scale the data. Use the `fit()` and `transform()` methods to obtain the normalized data matrix.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f335e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0db6a3b4",
   "metadata": {},
   "source": [
    "### 4. Visualizing the Data\n",
    "\n",
    "Before clustering, it is useful to represent the data in 2 dimensions to check whether they have a specific natural structure and if any clusters visually appear.\n",
    "\n",
    "1. Perform a PCA with 2 components using the `PCA` class from `sklearn.decomposition`. Compute the overall quality of the representation. \n",
    "\n",
    "2. Use the `transform()` method of the `PCA` class to obtain the principal components (coordinates of the observations on axes 0 and 1).\n",
    "\n",
    "3.  Represent the observations on the first principal plane using the `scatter()` function from `matplotlib.pyplot`. For each point, it is useful to write the hotel name and the star rating with the `text()` function from `matplotlib.pyplot`. \n",
    "\n",
    "4. Do any obvious clusters appear visually?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de2c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c8176c6",
   "metadata": {},
   "source": [
    "### 5. Agglomerative Hierarchical Clustering\n",
    "\n",
    "1. To implement agglomerative hierarchical clustering in Python, we use the `scipy.cluster.hierarchy` module, mainly the functions `dendrogram`, `linkage`, and `fcluster`. Study these functions.\n",
    "\n",
    "1. We will consider the Euclidean metric for calculating distances between points and different linkage methods for calculating distances between clusters: single, complete, average, centroid, and ward. \n",
    "    For each of these linkage methods:\n",
    "\n",
    "    1. Perform the full agglomerative hierarchical clustering using the `linkage` function (with parameter `optimal_ordering=True` for better visualization of the results). This function returns a linkage matrix.\n",
    "\n",
    "    1. Represent this linkage matrix as a dendrogram using the `dendrogram` function (with parameter `color_threshold=0` to obtain the full dendrogram).\n",
    "\n",
    "1. Visually identify the linkage method that produces the best partitions (homogeneous and well-separated clusters).\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f383b204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0171558",
   "metadata": {},
   "source": [
    "### 6. Agglomerative Hierarchical Clustering (continued)\n",
    "\n",
    "1. For the selected linkage method, propose a few (2 or 3) relevant values for the number $K$ of clusters.\n",
    "    For each value of $K$:\n",
    "    \n",
    "    1. Determine on the dendrogram the required threshold (or height) $t$ to cut the tree. Display the clusters in color on the dendrogram by running the `dendrogram` function again with `color_threshold=t`.\n",
    "\n",
    "    1. Perform clustering using the `fcluster` function with this threshold $t$ and the distance criterion (`criterion='distance'`). Print the result of the function, which is a vector containing, for each data point, the label (number) of its cluster.\n",
    "\n",
    "    1. To evaluate the quality of the clustering, calculate the silhouette score using the `silhouette.score` function from the `sklearn.metrics` module. \n",
    "\n",
    "1. Compare the results and determine the best partition (according to silhouette score).\n",
    "\n",
    "1. For this best partition, list the names and star ratings of the hotels in each cluster. To retrieve the indices of the hotels assigned to clusters, the simplest method is to use the `argsort` function from `numpy`: the returned indices correspond to the cluster labels sorted in ascending order.\n",
    "\n",
    "1. For cluster visualization, color the points belonging to the same cluster with a specific color on the previous 2D representation obtained by PCA. Analyze the clustering result. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0782e9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "074f2b62",
   "metadata": {},
   "source": [
    "### 7. K-Means\n",
    "\n",
    "1. To implement the K-means algorithm in Python, we use the `KMeans` class from the `sklearn.cluster` module. Study this class:\n",
    "- call parameters: `n_clusters`, `init`, and `n_init`,\n",
    "- attributes: `labels_`, `inertia_`, and `cluster_centers_`,\n",
    "- methods: `fit()`.\n",
    "\n",
    "1. Apply the K-means algorithm for a number of clusters $K$ of your choice, first with a random initialization (`init='random'`) and a single run (`n_init=1`). Compute the inertia of the obtained partition using the `inertia_` attribute and the silhouette score using the `silhouette.score` function from the `sklearn.metrics` module. \n",
    "\n",
    "1. Run the algorithm a second time, compute again the inertia and the silhouette score, and compare the new partition with the previous one by calculating the Adjusted Rand Index (ARI) using the `adjusted_rand_score` function from the `sklearn.metrics` module.\n",
    "\n",
    "1. Do the same with the `k-means++` initialization method and multiple runs (`n_init=10`). Comment on the stability of the K-means algorithm. \n",
    "\n",
    "1. Determine the optimal value of $K$ using the two methods seen in class: the elbow method and the silhouette method (you can vary $K$ from 2 to 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa5ba7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d8a4d94",
   "metadata": {},
   "source": [
    "### 8. K-Means (continued)\n",
    "\n",
    "1. For the optimal value of $K$, list the names and star ratings of the hotels in each cluster.\n",
    "\n",
    "1. Visualize the clustering in 2D and analyze the clustering result. \n",
    "\n",
    "1. Check whether it is possible to automatically retrieve the classification of hotels based on their stars. To do this, apply the K-means method with $K=6$, since there are $6$ star categories (0 to 5), and examine the relationship between the star rating of the hotels and their clusters. To quantify the matching between the clustering result (given by the `labels_` attribute) and the star classification (given by the ETOILE column), you can use the Adjusted Rand Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcc355c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
