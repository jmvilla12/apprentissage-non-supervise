{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25aad299",
   "metadata": {},
   "source": [
    "# UV TRNU.CSN - Data and Machine Learning\n",
    "## Unsupervised learning - TP PCA - 2025\n",
    "\n",
    "Christelle Garnier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0935aa6c",
   "metadata": {},
   "source": [
    "### Aim of the TP\n",
    "\n",
    "The aim of this practical work is:\n",
    "- to apply PCA (Principal Component Analysis) to real datasets by leveraging the classes and functions provided by the `Scikit-Learn` library. \n",
    "- to create graphical representations of both the observations and the variables using the `matplotlib` library to interpret the PCA results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9663c31a",
   "metadata": {},
   "source": [
    "### Dataset 'temperatures.csv'\n",
    "\n",
    "The work consists of performing a standardized PCA on the data contained in the file 'temperatures.csv' available on MyLearningSpace. \n",
    "\n",
    "Start by looking at the file. It contains data concerning about thirty European cities:\n",
    "- Meteorological data : average temperatures for each month of the year, mean and range of annual temperatures\n",
    "- Geographical data: latitude, longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc500f9",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3717f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#TODO ADD other needed libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9840f120",
   "metadata": {},
   "source": [
    "### 1. Reading the Data\n",
    "\n",
    "1. Load the file 'temperatures.csv' using `read_csv()` from the `pandas` library. Check the import by using the methods and attributes available for the `DataFrame` class, such as `info()`, `describe()`, `shape`, and `head()`.\n",
    "\n",
    "1. Store the first column separately, as you will need to label the \"observations\" in graphical representations of the principal components.\n",
    "\n",
    "1. Decide which variables to keep for PCA calculation and remove the unused columns with the `drop()` method of the `DataFrame` class.\n",
    "\n",
    "1. Save the names of the selected columns using the `columns` attribute of the `DataFrame` class, as you will need to label the \"variables\" in the correlation circle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf34263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f5f56f4",
   "metadata": {},
   "source": [
    "### 2. Exploring the Data\n",
    "\n",
    "Once the data for the PCA has been imported and selected, begin with a preliminary analysis to identify relationships between the variables.\n",
    "\n",
    "1. Compute the correlation coefficients between all pairs of numerical variables using the `corr()` method of the `DataFrame` class and visualize the correlation matrix as a heatmap using the `heatmap()` function from the `seaborn` library. \n",
    "\n",
    "1. In addition, you can also display scatter plots for all pairs of numerical variables using the `scatter_matrix()` function from `pandas.plotting`.\n",
    "\n",
    "1. Identify which variables are the most strongly correlated (positively and negatively), and which ones show the weakest correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca0183e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13297bb3",
   "metadata": {},
   "source": [
    "### 3. Preprocessing the Data\n",
    "To apply a standardized PCA, the data must be centered and scaled. There are several ways to do this, but the simplest approach is as follows:\n",
    "\n",
    "1. First, convert the `DataFrame` object into a `numpy` array, denoted as $\\mathbf{X}$ (following the course notation), by using the `to_numpy()` method of the `DataFrame` class.\n",
    "\n",
    "1. Next, use the `StandardScaler` class from `sklearn.preprocessing` to center and scale the data. Review this class, paying particular attention to the `fit()` and `transform()` methods, and then use them to obtain the normalized data matrix $\\mathbf{Z}$ (again following the course notation).\n",
    "\n",
    "1. Finally, verify that the mean and variance of the standardized variables are indeed 0 and 1, respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16544382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c8176c6",
   "metadata": {},
   "source": [
    "### 4. Performing the PCA\n",
    "\n",
    "Once the data has been standardized, you can carry out the Principal Component Analysis.\n",
    "\n",
    "1. Study the `PCA` class from `sklearn.decomposition`. Review the main attributes and methods of this class, especially `fit()`, `transform()`, `explained_variance_`, `explained_variance_ratio_`, and `components_`.\n",
    "\n",
    "2. Apply the PCA method to the standardized data $\\mathbf{Z}$ in order to compute all the eigenvalues and the principal vectors (eigenvectors). Check the sum of the eigenvalues, if necessary normalize the eigenvalues to obtain a sum equal to the number of variables.   \n",
    "\n",
    "3. Display the explained inertia (variance) per axis, the explained inertia ratio per axis and the cumulative explained inertia ratio using the `cumsum()` function from `numpy`.  \n",
    "\n",
    "4. Plot the scree plot (eigenvalue decay) and the cumulative explained inertia ratio curve using the `bar()` and `plot()` functions from `matplotlib.pyplot`.\n",
    "\n",
    "5. Determine the number of axes to retain using the three criteria discussed in the course. \n",
    "\n",
    "6. Precise the overall quality of the representation with the retained number of axes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6fa3a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "189da118",
   "metadata": {},
   "source": [
    "### 5. Projection of Observations\n",
    "\n",
    "The objective is to project the observations onto the principal axes. \n",
    "\n",
    "1. Apply the PCA method to the standardized data $\\mathbf{Z}$ using the retained number of components.\n",
    "\n",
    "1. Which formula from the course gives the coordinates of the observations in the considered subspace ?\n",
    "\n",
    "1. Use the `transform()` method of the `PCA` class to obtain the principal components. \n",
    "\n",
    "1. Represent the observations on the first principal plane spanned by the first 2 principal vectors (axes 0 and 1) using the `scatter()` function from `matplotlib.pyplot`. Label each point with the `text()` function from `matplotlib.pyplot`. Depending on the number of retained axes, you can also plot the second principal plane defined by axes 2 and 3.\n",
    "\n",
    "1. Compute the contribution of the observations to the inertia explained by each axis. Using these values and the graphical representations, identify the observations that contribute the most to each axis (both positively and negatively).\n",
    "\n",
    "1. Highlight similarities and differences between the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a43dd8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1395de1",
   "metadata": {},
   "source": [
    "### 6. Projection of Variables (Correlation Circle)\n",
    "\n",
    "The objective is now to project the variables inside the correlation circle onto the factorial axes. \n",
    "\n",
    "1. Which formula from the course gives the coordinates of the variables in the considered subspace ?\n",
    "\n",
    "1. Use the attribute `components_` of the `PCA` class to obtain the eigenvectors (or principal vectors) corresponding to the eigenvalues. Deduce the correlations between the original variables and the first principal factors.\n",
    "\n",
    "1. Represent the projected variables on the relevant factorial plane(s) with line segments or arrows starting from the origin. Label each point and draw the correlation circle with the `Circle()` function from `matplotlib.pyplot`.\n",
    "\n",
    "1. Find the strongly correlated variables (positively or negatively) and the weakly correlated variables. \n",
    "\n",
    "1. Determine which variables contribute most to each principal component (both positively and negatively) and provide an interpretation of the different axes. \n",
    "\n",
    "1. By combining the two projections (variables and observations), summarize the main insights provided by the PCA including: \n",
    "- interpretation of each axis (meaning of new variables), \n",
    "- groups of observations sharing similar characteristics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf7197f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73e85f9f",
   "metadata": {},
   "source": [
    "### 7. Extension to Other Data\n",
    "\n",
    "Extend this work by performing a standardized PCA on other datasets contained in the files 'decathlon_JO.txt' and 'activites.txt' available on MyLearningSpace.  \n",
    "\n",
    "#### Dataset 'decathlon_JO.txt'\n",
    "\n",
    "This dataset summarizes the performance of athletes at different athletics disciplines during the Olympic Games of Athens in 2004. \n",
    "\n",
    "In this file, the first column contains the names of the athletes. \n",
    "\n",
    "The following columns correspond to the variables including: \n",
    "- 10 quantitative variables: performances (100m, Long Jump, Shot Put, High Jump, 400m, 110m hurdles, Discus, Pole Vault, Javelin, 1500m)\n",
    "- 1 ordinal variable: ranking\n",
    "- 1 discrete variable: scored points\n",
    "- 1 qualitative variable: Olympic Games (Athens 2004)\n",
    "\n",
    "\n",
    "#### Dataset 'activites.txt'\n",
    "\n",
    "This dataset corresponds to a (slightly old) survey conducted on different populations about the time spent on various daily activities.\n",
    "\n",
    "In this file, the first column POP identifies groups of people. The codes used are as follows:\n",
    "H: Men, F: Women, A: Active, N: Non-active, M: Married, C: Single, U: USA, W: Western countries, E: Eastern countries, Y: Yugoslavia.\n",
    "\n",
    "The following columns correspond to the variables including:\n",
    "- 10 numerical variables which represent the time spent (in hundredths of an hour) on: PROFession, TRANsport, MENAge (housework), ENFAnts (children), COURses (shopping), TOILette (personal care), REPas (meals), SOMMeil (sleep), TELEvision, and LOISirs (leisure).\n",
    "- 4 categorical variables:\n",
    "SEXe (1 = Men, 2 = Women), \n",
    "ACTivité (1 = Active, 2 = Non-active, 9 = Not specified), \n",
    "état CIVil (1 = Single, 2 = Married, 9 = Not specified), \n",
    "PAYs (1 = USA, 2 = Western countries, 3 = Eastern countries, 4 = Yugoslavia).\n",
    "\n",
    "The times are expressed in hundredths of an hour. For example, the top-left cell (610) indicates that active men in the USA spend on average 6 hours and 6 minutes (10/100 of an hour) on their professional activity. The total over the 10 activities is 2400 (24 hours).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ecaec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
